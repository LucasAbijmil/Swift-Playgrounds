import Foundation
/*:
 # Grand Central Dispatch (GCD)
 * Le GCD permet de gÃ©rer une grande partie des performances d'une application
 * Il permet de faire de la programmation concurrente, du multi-threading, etc...
 */
/*:
 ## ExÃ©cution synchrone et asynchrone
 * **synchrone** :
    * Le programme attend que l'exÃ©cution d'une tÃ¢che se finisse avant de faire d'autres opÃ©rations. **Cette mÃ©thode bloque le processeur.**
    * Code qui s'exÃ©cute de "haut en bas" comme par exemple les fonctions avec des returns
 */
func presentationSynchrone() -> String {
  return "Lucas Abijmil"
}
/*:
 * **asynchrone** :
    * Le programme n'attends pas la fin de l'exÃ©cution d'une tÃ¢che pour faire d'autres opÃ©rations. **Cette mÃ©thode ne bloque pas le processeur.**
    * Le programme revient directemment sans attendre que la tÃ¢che soit finie, comme par exemple les fonctions sans return mais avec des @escaping closures
    * La mÃ©thode asynchrone est utilisÃ© dans de trÃ¨s nombreux cas en informatique : fetch depuis API, accÃ¨s Ã  des Databases, lecture d'un fichier etc...
    * Souvent utilisÃ© pour les tÃ¢ches potentiellement longues
 */
func presentationAsynchrone(then completion: @escaping (String) -> Void) {
  completion("Lucas Abijmil")
}
/*:
 ## DispatchQueue
 * Les tÃ¢ches du GCD s'organisent en queue (file d'attente), reprÃ©sentable par une file FIFO : First In, First Out
 * **Le GCD assure de lancer qu'une seule tÃ¢che Ã  la fois**
 */
/*:
 ## Il existe deux types de queues :
 * **serial** : DispatchQueue.main
    * Lance une seule tÃ¢che Ã  la fois (selon l'ordre de la file) et attend que cette tÃ¢che soit finit pour commencer l'exÃ©cution de la tÃ¢che suivante
    * **N'exÃ©cute qu'UNE SEULE tÃ¢che Ã  la fois**
    * [n, n+1, n+2]Â â€“â€“> lancement de la tÃ¢che n â€“â€“> fin de la tÃ¢che n â€“â€“> lancement de la tÃ¢che n+1 â€“â€“> fin de la tÃ¢che n+1 â€“â€“> lancement de la tÃ¢che n+2 â€“â€“> fin de la tÃ¢che n+2 => Ã  l'arrivÃ©e : [n, n+1, n+2]
 * **concurrent** : DispatchQueue.global
    * Lance une tÃ¢che Ã  la fois (selon l'ordre de la file) MAIS n'attend PAS la fin de cette tÃ¢che pour lancer l'exÃ©cution de la tÃ¢che suivante
    * **ExÃ©cute PLUSIEURS tÃ¢ches Ã  la fois et l'ordre de fin d'exÃ©cution de chaque tÃ¢che n'est pas prÃ©visible**
    * [n, n+1, n+2]Â â€“â€“> lancement de la tÃ¢che n â€“â€“> lancement de la tÃ¢che n+1 â€“â€“> lancement de la tÃ¢che n+2 => Ã  l'arrivÃ©e : [????]Â on ne peut pas savoir
 */
/*:
 ## Voici l'ordre d'importance des DispatchQueue (du plus prioritaire au moins prioritaire) :
 * `DispatchQueue.main` : Ã  utiliser uniquement pour update la UI â€“Â extrÃªme prioritÃ©
 * `DispatchQueue.global(qos: .userInteractive)` : animations, event handling â€“Â trÃ¨s forte prioritÃ©
 * `DispatchQueue.global(qos: .userInitiated)` : rÃ©sultats censÃ©s Ãªtre immÃ©diats (chargement de donnÃ©es depuis la UI, comme un boutton) â€“ forte prioritÃ©
 * `DispatchQueue.global(qos: .default)` ou `DispatchQueue.global()` : tÃ¢che que l'application initie d'elle mÃªme â€“Â prioritÃ© par dÃ©faut
 * `DispatchQueue.global(qos: .utility)` : tÃ¢che longues (mise en rÃ©seau, recherche continue de donnÃ©es) â€“Â faible prioritÃ©
 * `DispatchQueue.global(qos: .background)` : tÃ¢ches cachÃ©es Ã  l'utilisateur (prefetch / tÃ¢ches en background)
 */
DispatchQueue.main
DispatchQueue.global(qos: .userInteractive)
DispatchQueue.global(qos: .userInitiated)
DispatchQueue.global(qos: .default)
DispatchQueue.global()
DispatchQueue.global(qos: .utility)
DispatchQueue.global(qos: .background)
DispatchQueue.global(qos: .unspecified) // ??
/*:
 ## CrÃ©ations de nos propres DispatchQueue
 * CrÃ©ation d'une **Serial queue**
 */
DispatchQueue(label: "serialCustomQueue")
//: * CrÃ©ation dune **Concurrent queue**
DispatchQueue(label: "ConcurrentCustomQueue", qos: .default, attributes: .concurrent)
//: ### Exemple : exÃ©cution d'une tÃ¢che dans le background qui va mettre Ã  jour la UI tout Ã§a en mÃ©thode asynchone
DispatchQueue.global(qos: .background).async {
  // some code here
  DispatchQueue.main.async {
    // update UI here
  }
}
/*:
 ## DispatchQueue + Delay
 * PossibilitÃ© de delay un block de code mais **uniquement en asynchrone**
 * Disponible pour les queues **serial** & **concurrent**
 */
DispatchQueue.main.asyncAfter(deadline: .now() + .seconds(2)) { /* code executed after 2 seconds */ }
DispatchQueue.global(qos: .default).asyncAfter(deadline: .now() + .seconds(5)) { /* code executed after 5 seconds */ }
/*:
 ## DispatchWorkItem
 * Le GCD n'est rien d'aute qu'une liste de tÃ¢ches exÃ©cutÃ©es
 * Chaque tÃ¢che est donc par transition un `DispatchWorkItem` de type : `() -> Void`
 * Un `DispatchWorkItem` peut Ãªtre insÃ©rÃ© dans une `DispatchQueue` ou un `DispatchGroup`
 * Fonctions diponibles :
    * `perform` : exÃ©cution de la tÃ¢che
    * `wait` : applique un `DispatchTime` acvant tout prochaine action exÃ©cutÃ© par le `DispatchWorkItem`
    * `notify` : permet de notifier une queue que l'exÃ©cution du `DispatchWorkItem` est finie et d'exÃ©cuter du code dans la closure
    * `cancel` : annule l'exÃ©cution du `DispatchWorkItem`
    * `workItem.isCancelled` : boolÃ©en qui indique si la tÃ¢che a Ã©tÃ© annulÃ©e ou non
 */
//: * CrÃ©ation d'un `DispatchWorkItem`
let workItem = DispatchWorkItem {
  print("workItem is computing a task....")
}
//: * ExÃ©cution d'un `DispatchWorkItem`
DispatchQueue.global(qos: .default).async {
  workItem.perform()
}
//: * Notification d'une queue que le `DispatchWorkItem` a finit son exÃ©cution
workItem.notify(queue: .main) {
  print("workItem has finished its work")
}
//: ### Exemple un peu plus complexe
var workItemBis: DispatchWorkItem?
workItemBis = DispatchWorkItem {
  // La tÃ¢che est composÃ©e de "5 sous tÃ¢ches"
  for task in 0...5 {
    // unwrap de l'optionnel + vÃ©rification que la tÃ¢che n'est pas cancelled
    guard let workItem = workItemBis, !workItem.isCancelled else { print("workItemBis has been canceled"); break }

    // exÃ©cution de la tÃ¢che aprÃ¨s un delay de 1 secondes
    workItem.wait(timeout: .now() + .seconds(1))
    print("workItemBis is computing task nÂ°\(task)")
  }
}
DispatchQueue.global(qos: .default).async(execute: workItemBis!) // pareil que .async {Â workItemBis!.perform() }
// Annulation de la tÃ¢ches aprÃ¨s un delay de 2 secondes
DispatchQueue.global(qos: .default).asyncAfter(deadline: .now() + .seconds(2)) { workItemBis?.cancel() }
/*:
 ## DispatchGroup
 * Permet d'attendre que toutes les tÃ¢ches d'un groupe soient finies avant de conitunuer l'exÃ©cution
 * Rend un ensemble de tÃ¢ches **asynchrones synchronisÃ©s**, tout en laissant chaque sous-tÃ¢ches **asynchrones**
 * `DispatchGroup` est trÃ¨s utile pour fetch des datas depuis plusieurs APIs qui ont besoin d'Ãªtre "rassebmlÃ©es"
 * Fonctions dispnibles :
    * `enter` : indique le dÃ©but d'exÃ©cution d'une tÃ¢che du `DispatchGroup`
    * `leave` : indique la fin d'exÃ©cution d'une tÃ¢che du `DispatchGroup`
    * `notify` : permet de notifier une queue que l'exÃ©cution du `DispatchGroup` est finie et d'exÃ©cuter du code dans la closure
    * `wait` : permet d'appliquer un `DispatchTime` sur un `DispatchGroup`
 * Fonctionnement : le count du `DispatchGroup` doit toujours Ãªtre Ã  9 Ã  la fin d'exÃ©cution de toutes les tÃ¢ches
    * `group.enter()` : +1 au count du groupe
    * `group.leaver()` : -1 au count du groupe

 */
//: * CrÃ©ation du `DispatchGroup`
let group = DispatchGroup()
func fetchSomeData(completion: @escaping () -> Void) { completion() }

func fetchAllData() {
  group.enter() // group += 1
  fetchSomeData {
    print("Fetching some data from API nÂ°1 ...")
    sleep(1)
    print("Fetch nÂ°1 completed")
    group.leave() // group -= 1
  }

  group.enter() // group += 1
  fetchSomeData {
    print("Fetching some data from API nÂ°2 ...")
    sleep(2)
    print("Fetch nÂ°2 completed")
    group.leave() // group -= 1
  }

  group.enter() // group += 1
  fetchSomeData {
    print("Fetching some data from API nÂ°3 ...")
    sleep(3)
    print("Fetch nÂ°3 completed")
    group.leave() // group -= 1
  }
}

fetchAllData()
//: * Note : exÃ©cution de la closure uniquement si le count du `DispatchGroup` est 0 et si toutes les tÃ¢ches ont finis leur travail
group.notify(queue: .main) {
  print("All data from all APIs are fetched")
}
/*:
 ## DispatchSemaphore
 * Permet de restreindre l'accÃ¨s Ã  une ressource partagÃ©e (Database, cache...) par plusieurs thread (systÃ¨me concurrent)
 * Rend une tÃ¢che **asynchrone en synchrone** â€“â€“> les queues utilisent les sÃ©maphores que de maniÃ¨re asynchrone
 * Fonctions disponibles :
    * `wait` : permet d'indiquer qu'on utilise la ressource partagÃ©e (si celle-ci es disponible, sinon on wait)
    * `signal` : permet d'indiquer la fin de l'utilisation de la ressource partagÃ©e
 * Fonctionnement :
    * Ã  l'init du `DispatchSemaphore` on inidque le nombre de threads autorisÃ©s Ã  utiliser ka ressource simultanÃ©ment
    * `sempahore.wait` : -1 Ã  la value du semaphore
    * `semaphore.signal` : +1 Ã  la value du semaphore
    * Si **value > 0** : d'autres threads peuvent utiliser la ressource partagÃ©e
    * Si **value = 0** : aucun autre thread ne peut utiliser la ressource partagÃ©e
 * **Tip** : ne **jamais** utilisÃ© `semaphore.wait()` sur le main thread sinon crash
 */
//: * CrÃ©ation d'un `DispatchSemaphore` avec une value de 1 ğŸ‘‰ un seul thread est authorisÃ© Ã  accÃ©der Ã  la ressource partagÃ©e
let semaphore = DispatchSemaphore(value: 1)
DispatchQueue.global(qos: .default).async {
  print("Task 1 â€“ wait")
  semaphore.wait() // value -= 1 (value = 0 â€“â€“> ressource partagÃ©e plus accessible par les autres threads)
  sleep(1) // comme un DispatchTime de 1 seconde
  semaphore.signal() // value += 1 (value = 1 â€“â€“> ressource partagÃ©e Ã  nouveau accessible par les autres threads)
  print("Task 1 â€“ done")
}

DispatchQueue.global(qos: .default).async {
  print("Task 2 â€“ wait")
  semaphore.wait() // value -= 1 (value = 0 â€“â€“> ressource partagÃ©e plus accessible par les autres threads)
  sleep(1)
  semaphore.signal() // value += 1 (value = 1 â€“â€“> ressource partagÃ©e Ã  nouveau accessible par les autres threads)
  print("Task 2 â€“ done")
}

DispatchQueue.global(qos: .default).async {
  print("Task 3 â€“ wait")
  semaphore.wait() // value -= 1 (value = 0 â€“â€“> ressource partagÃ©e plu saccessible par les autres threads)
  sleep(1)
  semaphore.signal() // value += 1 (value = 1 â€“â€“> ressource partagÃ©e Ã  nouveau accessible par les autres threads)
  print("Task 3 â€“ done")
}
/*:
 ## DispatchSource
 * Permet de surveiller des fichiers, ports, signaux...
 * Pas trÃ¨s utilisÃ© dans la pratique car objet de bas niveau
 * Aller voir la doc d'Apple pour la suite
 */
let timer = DispatchSource.makeTimerSource()
timer.schedule(deadline: .now(), repeating: .seconds(1))
timer.setEventHandler {
  print("Hello there")
}
timer.resume()
