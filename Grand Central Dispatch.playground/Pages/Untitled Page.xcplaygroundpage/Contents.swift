import Foundation
/*:
 # Grand Central Dispatch (GCD)
 * Le GCD permet de g√©rer une grande partie des performances d'une application
 * Il permet de faire de la programmation concurrente, du multi-threading, etc...
 */
/*:
 ## Ex√©cution synchrone et asynchrone
 * **synchrone** :
    * Le programme attend que l'ex√©cution d'une t√¢che se finisse avant de faire d'autres op√©rations. **Cette m√©thode bloque le processeur.**
    * Code qui s'ex√©cute de "haut en bas" comme par exemple les fonctions avec des returns
 */
func presentationSynchrone() -> String {
  return "Lucas Abijmil"
}
/*:
 * **asynchrone** :
    * Le programme n'attends pas la fin de l'ex√©cution d'une t√¢che pour faire d'autres op√©rations. **Cette m√©thode ne bloque pas le processeur.**
    * Le programme revient directemment sans attendre que la t√¢che soit finie, comme par exemple les fonctions sans return mais avec des @escaping closures
    * La m√©thode asynchrone est utilis√© dans de tr√®s nombreux cas en informatique : fetch depuis API, acc√®s √† des Databases, lecture d'un fichier etc...
    * Souvent utilis√© pour les t√¢ches potentiellement longues
 */
func presentationAsynchrone(then completion: @escaping (String) -> Void) {
  completion("Lucas Abijmil")
}
/*:
 ## DispatchQueue
 * Les t√¢ches du GCD s'organisent en queue (file d'attente), repr√©sentable par une file FIFO : First In, First Out
 * **Le GCD assure de lancer qu'une seule t√¢che √† la fois**
 */
/*:
 ## Il existe deux types de queues :
 * **serial** : DispatchQueue.main
    * Lance une seule t√¢che √† la fois (selon l'ordre de la file) et attend que cette t√¢che soit finit pour commencer l'ex√©cution de la t√¢che suivante
    * **N'ex√©cute qu'UNE SEULE t√¢che √† la fois**
    * [n, n+1, n+2]¬†‚Äì‚Äì> lancement de la t√¢che n ‚Äì‚Äì> fin de la t√¢che n ‚Äì‚Äì> lancement de la t√¢che n+1 ‚Äì‚Äì> fin de la t√¢che n+1 ‚Äì‚Äì> lancement de la t√¢che n+2 ‚Äì‚Äì> fin de la t√¢che n+2 => √† l'arriv√©e : [n, n+1, n+2]
 * **concurrent** : DispatchQueue.global
    * Lance une t√¢che √† la fois (selon l'ordre de la file) MAIS n'attend PAS la fin de cette t√¢che pour lancer l'ex√©cution de la t√¢che suivante
    * **Ex√©cute PLUSIEURS t√¢ches √† la fois et l'ordre de fin d'ex√©cution de chaque t√¢che n'est pas pr√©visible**
    * [n, n+1, n+2]¬†‚Äì‚Äì> lancement de la t√¢che n ‚Äì‚Äì> lancement de la t√¢che n+1 ‚Äì‚Äì> lancement de la t√¢che n+2 => √† l'arriv√©e : [????]¬†on ne peut pas savoir
 */
/*:
 ## Voici l'ordre d'importance des DispatchQueue (du plus prioritaire au moins prioritaire) :
 * `DispatchQueue.main` : √† utiliser uniquement pour update la UI ‚Äì¬†extr√™me priorit√©
 * `DispatchQueue.global(qos: .userInteractive)` : animations, event handling ‚Äì¬†tr√®s forte priorit√©
 * `DispatchQueue.global(qos: .userInitiated)` : r√©sultats cens√©s √™tre imm√©diats (chargement de donn√©es depuis la UI, comme un boutton) ‚Äì forte priorit√©
 * `DispatchQueue.global(qos: .default)` ou `DispatchQueue.global()` : t√¢che que l'application initie d'elle m√™me ‚Äì¬†priorit√© par d√©faut
 * `DispatchQueue.global(qos: .utility)` : t√¢che longues (mise en r√©seau, recherche continue de donn√©es) ‚Äì¬†faible priorit√©
 * `DispatchQueue.global(qos: .background)` : t√¢ches cach√©es √† l'utilisateur (prefetch / t√¢ches en background)
 */
DispatchQueue.main
DispatchQueue.global(qos: .userInteractive)
DispatchQueue.global(qos: .userInitiated)
DispatchQueue.global(qos: .default)
DispatchQueue.global()
DispatchQueue.global(qos: .utility)
DispatchQueue.global(qos: .background)
DispatchQueue.global(qos: .unspecified) // ??
/*:
 ## Cr√©ations de nos propres DispatchQueue
 * Cr√©ation d'une **Serial queue**
 */
DispatchQueue(label: "serialCustomQueue")
//: * Cr√©ation dune **Concurrent queue**
DispatchQueue(label: "ConcurrentCustomQueue", qos: .default, attributes: .concurrent)
//: ### Exemple : ex√©cution d'une t√¢che dans le background qui va mettre √† jour la UI tout √ßa en m√©thode asynchone
DispatchQueue.global(qos: .background).async {
  // some code here
  DispatchQueue.main.async {
    // update UI here
  }
}
/*:
 ## DispatchQueue + Delay
 * Possibilit√© de delay un block de code mais **uniquement en asynchrone**
 * Disponible pour les queues **serial** & **concurrent**
 */
DispatchQueue.main.asyncAfter(deadline: .now() + .seconds(2)) { /* code executed after 2 seconds */ }
DispatchQueue.global(qos: .default).asyncAfter(deadline: .now() + .seconds(5)) { /* code executed after 5 seconds */ }
/*:
 ## DispatchWorkItem
 * Le GCD n'est rien d'aute qu'une liste de t√¢ches ex√©cut√©es
 * Chaque t√¢che est donc par transition un `DispatchWorkItem` de type : `() -> Void`
 * Un `DispatchWorkItem` peut √™tre ins√©r√© dans une `DispatchQueue` ou un `DispatchGroup`
 * Fonctions diponibles :
    * `perform` : ex√©cution de la t√¢che
    * `wait` : applique un `DispatchTime` acvant tout prochaine action ex√©cut√© par le `DispatchWorkItem`
    * `notify` : permet de notifier une queue que l'ex√©cution du `DispatchWorkItem` est finie et d'ex√©cuter du code dans la closure
    * `cancel` : annule l'ex√©cution du `DispatchWorkItem`
    * `workItem.isCancelled` : bool√©en qui indique si la t√¢che a √©t√© annul√©e ou non
 */
//: * Cr√©ation d'un `DispatchWorkItem`
let workItem = DispatchWorkItem {
  print("workItem is computing a task....")
}
//: * Ex√©cution d'un `DispatchWorkItem`
DispatchQueue.global(qos: .default).async {
  workItem.perform()
}
//: * Notification d'une queue que le `DispatchWorkItem` a finit son ex√©cution
workItem.notify(queue: .main) {
  print("workItem has finished its work")
}
//: ### Exemple un peu plus complexe
var workItemBis: DispatchWorkItem?
workItemBis = DispatchWorkItem {
  // La t√¢che est compos√©e de "5 sous t√¢ches"
  for task in 0...5 {
    // unwrap de l'optionnel + v√©rification que la t√¢che n'est pas cancelled
    guard let workItem = workItemBis, !workItem.isCancelled else { print("workItemBis has been canceled"); break }

    // ex√©cution de la t√¢che apr√®s un delay de 1 secondes
    workItem.wait(timeout: .now() + .seconds(1))
    print("workItemBis is computing task n¬∞\(task)")
  }
}
DispatchQueue.global(qos: .default).async(execute: workItemBis!) // pareil que .async {¬†workItemBis!.perform() }
// Annulation de la t√¢ches apr√®s un delay de 2 secondes
DispatchQueue.global(qos: .default).asyncAfter(deadline: .now() + .seconds(2)) { workItemBis?.cancel() }
/*:
 ## DispatchGroup
 * Permet d'attendre que toutes les t√¢ches d'un groupe soient finies avant de conitunuer l'ex√©cution
 * Rend un ensemble de t√¢ches **asynchrones synchronis√©s**, tout en laissant chaque sous-t√¢ches **asynchrones**
 * `DispatchGroup` est tr√®s utile pour fetch des datas depuis plusieurs APIs qui ont besoin d'√™tre "rassebml√©es"
 * Fonctions dispnibles :
    * `enter` : indique le d√©but d'ex√©cution d'une t√¢che du `DispatchGroup`
    * `leave` : indique la fin d'ex√©cution d'une t√¢che du `DispatchGroup`
    * `notify` : permet de notifier une queue que l'ex√©cution du `DispatchGroup` est finie et d'ex√©cuter du code dans la closure
    * `wait` : permet d'appliquer un `DispatchTime` sur un `DispatchGroup`
 * Fonctionnement : le count du `DispatchGroup` doit toujours √™tre √† 9 √† la fin d'ex√©cution de toutes les t√¢ches
    * `group.enter()` : +1 au count du groupe
    * `group.leaver()` : -1 au count du groupe

 */
//: * Cr√©ation du `DispatchGroup`
let group = DispatchGroup()
func fetchSomeData(completion: @escaping () -> Void) { completion() }

func fetchAllData() {
  group.enter() // group += 1
  fetchSomeData {
    print("Fetching some data from API n¬∞1 ...")
    sleep(1)
    print("Fetch n¬∞1 completed")
    group.leave() // group -= 1
  }

  group.enter() // group += 1
  fetchSomeData {
    print("Fetching some data from API n¬∞2 ...")
    sleep(2)
    print("Fetch n¬∞2 completed")
    group.leave() // group -= 1
  }

  group.enter() // group += 1
  fetchSomeData {
    print("Fetching some data from API n¬∞3 ...")
    sleep(3)
    print("Fetch n¬∞3 completed")
    group.leave() // group -= 1
  }
}

fetchAllData()
//: * Note : ex√©cution de la closure uniquement si le count du `DispatchGroup` est 0 et si toutes les t√¢ches ont finis leur travail
group.notify(queue: .main) {
  print("All data from all APIs are fetched")
}
/*:
 ## DispatchSemaphore
 * Permet de restreindre l'acc√®s √† une ressource partag√©e (Database, cache...) par plusieurs thread (syst√®me concurrent)
 * Rend une t√¢che **asynchrone en synchrone** ‚Äì‚Äì> les queues utilisent les s√©maphores que de mani√®re asynchrone
 * Fonctions disponibles :
    * `wait` : permet d'indiquer qu'on utilise la ressource partag√©e (si celle-ci es disponible, sinon on wait)
    * `signal` : permet d'indiquer la fin de l'utilisation de la ressource partag√©e
 * Fonctionnement :
    * √† l'init du `DispatchSemaphore` on inidque le nombre de threads autoris√©s √† utiliser ka ressource simultan√©ment
    * `sempahore.wait` : -1 √† la value du semaphore
    * `semaphore.signal` : +1 √† la value du semaphore
    * Si **value > 0** : d'autres threads peuvent utiliser la ressource partag√©e
    * Si **value = 0** : aucun autre thread ne peut utiliser la ressource partag√©e
 * **Tip** : ne **jamais** utilis√© `semaphore.wait()` sur le main thread sinon crash
 */
//: * Cr√©ation d'un `DispatchSemaphore` avec une value de 1 üëâ un seul thread est authoris√© √† acc√©der √† la ressource partag√©e
let semaphore = DispatchSemaphore(value: 1)
DispatchQueue.global(qos: .default).async {
  print("Task 1 ‚Äì wait")
  semaphore.wait() // value -= 1 (value = 0 ‚Äì‚Äì> ressource partag√©e plus accessible par les autres threads)
  sleep(1) // comme un DispatchTime de 1 seconde
  semaphore.signal() // value += 1 (value = 1 ‚Äì‚Äì> ressource partag√©e √† nouveau accessible par les autres threads)
  print("Task 1 ‚Äì done")
}

DispatchQueue.global(qos: .default).async {
  print("Task 2 ‚Äì wait")
  semaphore.wait() // value -= 1 (value = 0 ‚Äì‚Äì> ressource partag√©e plus accessible par les autres threads)
  sleep(1)
  semaphore.signal() // value += 1 (value = 1 ‚Äì‚Äì> ressource partag√©e √† nouveau accessible par les autres threads)
  print("Task 2 ‚Äì done")
}

DispatchQueue.global(qos: .default).async {
  print("Task 3 ‚Äì wait")
  semaphore.wait() // value -= 1 (value = 0 ‚Äì‚Äì> ressource partag√©e plu saccessible par les autres threads)
  sleep(1)
  semaphore.signal() // value += 1 (value = 1 ‚Äì‚Äì> ressource partag√©e √† nouveau accessible par les autres threads)
  print("Task 3 ‚Äì done")
}
/*:
 ## DispatchSource
 * Permet de surveiller des fichiers, ports, signaux...
 * Pas tr√®s utilis√© dans la pratique car objet de bas niveau
 * Aller voir la doc d'Apple pour la suite
 */
let timer = DispatchSource.makeTimerSource()
timer.schedule(deadline: .now(), repeating: .seconds(1))
timer.setEventHandler {
  print("Hello there")
}
timer.resume()
